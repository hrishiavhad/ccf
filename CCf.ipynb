{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f4b50a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b760a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>406</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4462</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6986</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7519</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9487</th>\n",
       "      <td>136765</td>\n",
       "      <td>-5.493186</td>\n",
       "      <td>4.057918</td>\n",
       "      <td>-1.795148</td>\n",
       "      <td>-0.522112</td>\n",
       "      <td>-3.901231</td>\n",
       "      <td>-0.338767</td>\n",
       "      <td>-4.216907</td>\n",
       "      <td>1.655481</td>\n",
       "      <td>-0.030593</td>\n",
       "      <td>...</td>\n",
       "      <td>2.827709</td>\n",
       "      <td>-0.480805</td>\n",
       "      <td>0.883135</td>\n",
       "      <td>0.476372</td>\n",
       "      <td>-0.422392</td>\n",
       "      <td>0.266097</td>\n",
       "      <td>-1.249686</td>\n",
       "      <td>-0.237272</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9488</th>\n",
       "      <td>137949</td>\n",
       "      <td>1.939843</td>\n",
       "      <td>-0.434933</td>\n",
       "      <td>-0.345178</td>\n",
       "      <td>0.307799</td>\n",
       "      <td>-0.487803</td>\n",
       "      <td>0.113880</td>\n",
       "      <td>-0.729222</td>\n",
       "      <td>0.152521</td>\n",
       "      <td>1.132059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246981</td>\n",
       "      <td>0.914658</td>\n",
       "      <td>0.141960</td>\n",
       "      <td>0.799542</td>\n",
       "      <td>-0.099047</td>\n",
       "      <td>-0.270436</td>\n",
       "      <td>0.035708</td>\n",
       "      <td>-0.038128</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9489</th>\n",
       "      <td>138612</td>\n",
       "      <td>1.798427</td>\n",
       "      <td>-0.160432</td>\n",
       "      <td>-1.920048</td>\n",
       "      <td>1.051255</td>\n",
       "      <td>1.204895</td>\n",
       "      <td>0.892956</td>\n",
       "      <td>0.324847</td>\n",
       "      <td>0.194731</td>\n",
       "      <td>0.026695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176878</td>\n",
       "      <td>0.684760</td>\n",
       "      <td>-0.019825</td>\n",
       "      <td>-1.506229</td>\n",
       "      <td>0.238479</td>\n",
       "      <td>-0.389693</td>\n",
       "      <td>0.019441</td>\n",
       "      <td>-0.080415</td>\n",
       "      <td>55.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9490</th>\n",
       "      <td>165405</td>\n",
       "      <td>2.114637</td>\n",
       "      <td>-0.211168</td>\n",
       "      <td>-1.638108</td>\n",
       "      <td>-0.010894</td>\n",
       "      <td>0.490466</td>\n",
       "      <td>-0.130107</td>\n",
       "      <td>-0.015770</td>\n",
       "      <td>-0.042934</td>\n",
       "      <td>0.528540</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339011</td>\n",
       "      <td>-0.921378</td>\n",
       "      <td>0.170633</td>\n",
       "      <td>-1.413620</td>\n",
       "      <td>-0.180180</td>\n",
       "      <td>0.266670</td>\n",
       "      <td>-0.082983</td>\n",
       "      <td>-0.086125</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9491</th>\n",
       "      <td>77984</td>\n",
       "      <td>-0.298551</td>\n",
       "      <td>1.100801</td>\n",
       "      <td>0.841074</td>\n",
       "      <td>-0.335169</td>\n",
       "      <td>0.714700</td>\n",
       "      <td>0.023175</td>\n",
       "      <td>0.624201</td>\n",
       "      <td>0.112563</td>\n",
       "      <td>-0.671196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.282316</td>\n",
       "      <td>-0.739245</td>\n",
       "      <td>-0.182471</td>\n",
       "      <td>-0.871434</td>\n",
       "      <td>-0.013802</td>\n",
       "      <td>0.124734</td>\n",
       "      <td>0.244955</td>\n",
       "      <td>0.077531</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9492 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0        406 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "1        472 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "2       4462 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "3       6986 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "4       7519  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "9487  136765 -5.493186  4.057918 -1.795148 -0.522112 -3.901231 -0.338767   \n",
       "9488  137949  1.939843 -0.434933 -0.345178  0.307799 -0.487803  0.113880   \n",
       "9489  138612  1.798427 -0.160432 -1.920048  1.051255  1.204895  0.892956   \n",
       "9490  165405  2.114637 -0.211168 -1.638108 -0.010894  0.490466 -0.130107   \n",
       "9491   77984 -0.298551  1.100801  0.841074 -0.335169  0.714700  0.023175   \n",
       "\n",
       "            V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0    -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n",
       "1     0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "2     0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726   \n",
       "3    -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n",
       "4     1.713445 -0.496358 -1.282858  ... -0.379068 -0.704181 -0.656805   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9487 -4.216907  1.655481 -0.030593  ...  2.827709 -0.480805  0.883135   \n",
       "9488 -0.729222  0.152521  1.132059  ...  0.246981  0.914658  0.141960   \n",
       "9489  0.324847  0.194731  0.026695  ...  0.176878  0.684760 -0.019825   \n",
       "9490 -0.015770 -0.042934  0.528540  ... -0.339011 -0.921378  0.170633   \n",
       "9491  0.624201  0.112563 -0.671196  ... -0.282316 -0.739245 -0.182471   \n",
       "\n",
       "           V24       V25       V26       V27       V28  Amount  Class  \n",
       "0     0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "1    -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "2    -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "3    -0.053502  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "4    -1.632653  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "...        ...       ...       ...       ...       ...     ...    ...  \n",
       "9487  0.476372 -0.422392  0.266097 -1.249686 -0.237272    0.74      0  \n",
       "9488  0.799542 -0.099047 -0.270436  0.035708 -0.038128    9.99      0  \n",
       "9489 -1.506229  0.238479 -0.389693  0.019441 -0.080415   55.00      0  \n",
       "9490 -1.413620 -0.180180  0.266670 -0.082983 -0.086125    1.98      0  \n",
       "9491 -0.871434 -0.013802  0.124734  0.244955  0.077531    1.98      0  \n",
       "\n",
       "[9492 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('credit-card.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "669cbe6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1457a3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "df[['Time','Amount']].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4c0ec30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.153592</td>\n",
       "      <td>-0.065739</td>\n",
       "      <td>-0.155990</td>\n",
       "      <td>-0.126358</td>\n",
       "      <td>0.178835</td>\n",
       "      <td>-0.026117</td>\n",
       "      <td>0.116719</td>\n",
       "      <td>-0.072224</td>\n",
       "      <td>0.041552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009050</td>\n",
       "      <td>0.120674</td>\n",
       "      <td>0.057309</td>\n",
       "      <td>-0.014907</td>\n",
       "      <td>-0.230721</td>\n",
       "      <td>-0.039468</td>\n",
       "      <td>-0.043728</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>-0.005228</td>\n",
       "      <td>-0.067392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>0.153592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338804</td>\n",
       "      <td>0.537571</td>\n",
       "      <td>-0.336351</td>\n",
       "      <td>0.424820</td>\n",
       "      <td>0.148526</td>\n",
       "      <td>0.576406</td>\n",
       "      <td>-0.072854</td>\n",
       "      <td>0.294227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027774</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>-0.021855</td>\n",
       "      <td>-0.029900</td>\n",
       "      <td>0.013148</td>\n",
       "      <td>0.055246</td>\n",
       "      <td>-0.059056</td>\n",
       "      <td>-0.149922</td>\n",
       "      <td>-0.393192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>-0.065739</td>\n",
       "      <td>-0.338804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.472027</td>\n",
       "      <td>0.289252</td>\n",
       "      <td>-0.430043</td>\n",
       "      <td>-0.059691</td>\n",
       "      <td>-0.436903</td>\n",
       "      <td>0.022213</td>\n",
       "      <td>-0.300212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075674</td>\n",
       "      <td>-0.019794</td>\n",
       "      <td>0.065956</td>\n",
       "      <td>-0.010173</td>\n",
       "      <td>0.036848</td>\n",
       "      <td>-0.001541</td>\n",
       "      <td>-0.028841</td>\n",
       "      <td>-0.058482</td>\n",
       "      <td>-0.398742</td>\n",
       "      <td>0.385028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>-0.155990</td>\n",
       "      <td>0.537571</td>\n",
       "      <td>-0.472027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.461475</td>\n",
       "      <td>0.538608</td>\n",
       "      <td>0.212974</td>\n",
       "      <td>0.682578</td>\n",
       "      <td>-0.139669</td>\n",
       "      <td>0.416900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018827</td>\n",
       "      <td>-0.012436</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>0.011504</td>\n",
       "      <td>-0.031845</td>\n",
       "      <td>-0.015140</td>\n",
       "      <td>0.041601</td>\n",
       "      <td>-0.011104</td>\n",
       "      <td>-0.106823</td>\n",
       "      <td>-0.586907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>-0.126358</td>\n",
       "      <td>-0.336351</td>\n",
       "      <td>0.289252</td>\n",
       "      <td>-0.461475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.298284</td>\n",
       "      <td>-0.148585</td>\n",
       "      <td>-0.455635</td>\n",
       "      <td>0.063614</td>\n",
       "      <td>-0.347880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024099</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-0.027029</td>\n",
       "      <td>-0.003095</td>\n",
       "      <td>0.036056</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>0.020159</td>\n",
       "      <td>0.068051</td>\n",
       "      <td>0.546648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>0.178835</td>\n",
       "      <td>0.424820</td>\n",
       "      <td>-0.430043</td>\n",
       "      <td>0.538608</td>\n",
       "      <td>-0.298284</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.132061</td>\n",
       "      <td>0.585705</td>\n",
       "      <td>-0.150808</td>\n",
       "      <td>0.331799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011328</td>\n",
       "      <td>-0.024251</td>\n",
       "      <td>-0.011269</td>\n",
       "      <td>-0.011593</td>\n",
       "      <td>-0.028612</td>\n",
       "      <td>0.025527</td>\n",
       "      <td>0.100064</td>\n",
       "      <td>0.012223</td>\n",
       "      <td>-0.228017</td>\n",
       "      <td>-0.365313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>-0.026117</td>\n",
       "      <td>0.148526</td>\n",
       "      <td>-0.059691</td>\n",
       "      <td>0.212974</td>\n",
       "      <td>-0.148585</td>\n",
       "      <td>0.132061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128049</td>\n",
       "      <td>-0.188177</td>\n",
       "      <td>0.120740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015312</td>\n",
       "      <td>0.017347</td>\n",
       "      <td>0.070587</td>\n",
       "      <td>-0.015520</td>\n",
       "      <td>-0.030894</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>-0.080781</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>0.157301</td>\n",
       "      <td>-0.222903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>0.116719</td>\n",
       "      <td>0.576406</td>\n",
       "      <td>-0.436903</td>\n",
       "      <td>0.682578</td>\n",
       "      <td>-0.455635</td>\n",
       "      <td>0.585705</td>\n",
       "      <td>0.128049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027668</td>\n",
       "      <td>0.444805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032777</td>\n",
       "      <td>-0.033019</td>\n",
       "      <td>-0.043089</td>\n",
       "      <td>-0.005589</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>-0.003199</td>\n",
       "      <td>0.074117</td>\n",
       "      <td>0.063947</td>\n",
       "      <td>0.155748</td>\n",
       "      <td>-0.532240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>-0.072224</td>\n",
       "      <td>-0.072854</td>\n",
       "      <td>0.022213</td>\n",
       "      <td>-0.139669</td>\n",
       "      <td>0.063614</td>\n",
       "      <td>-0.150808</td>\n",
       "      <td>-0.188177</td>\n",
       "      <td>0.027668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.050410</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145706</td>\n",
       "      <td>0.040159</td>\n",
       "      <td>-0.199210</td>\n",
       "      <td>0.014176</td>\n",
       "      <td>0.069131</td>\n",
       "      <td>0.018408</td>\n",
       "      <td>0.161306</td>\n",
       "      <td>-0.021775</td>\n",
       "      <td>-0.038307</td>\n",
       "      <td>0.065579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>0.041552</td>\n",
       "      <td>0.294227</td>\n",
       "      <td>-0.300212</td>\n",
       "      <td>0.416900</td>\n",
       "      <td>-0.347880</td>\n",
       "      <td>0.331799</td>\n",
       "      <td>0.120740</td>\n",
       "      <td>0.444805</td>\n",
       "      <td>-0.050410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041952</td>\n",
       "      <td>-0.068406</td>\n",
       "      <td>-0.003574</td>\n",
       "      <td>0.020355</td>\n",
       "      <td>-0.000761</td>\n",
       "      <td>-0.023971</td>\n",
       "      <td>0.056621</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>-0.033937</td>\n",
       "      <td>-0.431281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>0.090201</td>\n",
       "      <td>0.461892</td>\n",
       "      <td>-0.443536</td>\n",
       "      <td>0.638050</td>\n",
       "      <td>-0.477917</td>\n",
       "      <td>0.485033</td>\n",
       "      <td>0.198203</td>\n",
       "      <td>0.668804</td>\n",
       "      <td>-0.063814</td>\n",
       "      <td>0.467092</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003417</td>\n",
       "      <td>-0.068820</td>\n",
       "      <td>-0.005168</td>\n",
       "      <td>0.017805</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>-0.011732</td>\n",
       "      <td>0.070480</td>\n",
       "      <td>0.058080</td>\n",
       "      <td>-0.044629</td>\n",
       "      <td>-0.646016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>-0.239900</td>\n",
       "      <td>-0.329347</td>\n",
       "      <td>0.317739</td>\n",
       "      <td>-0.487018</td>\n",
       "      <td>0.422903</td>\n",
       "      <td>-0.330921</td>\n",
       "      <td>-0.185495</td>\n",
       "      <td>-0.471116</td>\n",
       "      <td>0.109537</td>\n",
       "      <td>-0.367387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103983</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>-0.009979</td>\n",
       "      <td>-0.035886</td>\n",
       "      <td>0.019952</td>\n",
       "      <td>0.038492</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.025035</td>\n",
       "      <td>0.010215</td>\n",
       "      <td>0.594135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>0.140374</td>\n",
       "      <td>0.411815</td>\n",
       "      <td>-0.414163</td>\n",
       "      <td>0.607054</td>\n",
       "      <td>-0.517222</td>\n",
       "      <td>0.438550</td>\n",
       "      <td>0.221911</td>\n",
       "      <td>0.604248</td>\n",
       "      <td>-0.117515</td>\n",
       "      <td>0.458851</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087254</td>\n",
       "      <td>-0.041383</td>\n",
       "      <td>0.008283</td>\n",
       "      <td>0.017082</td>\n",
       "      <td>0.007290</td>\n",
       "      <td>-0.028776</td>\n",
       "      <td>-0.036853</td>\n",
       "      <td>-0.012147</td>\n",
       "      <td>-0.005060</td>\n",
       "      <td>-0.701934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>-0.067214</td>\n",
       "      <td>-0.032153</td>\n",
       "      <td>0.010934</td>\n",
       "      <td>-0.017727</td>\n",
       "      <td>0.004350</td>\n",
       "      <td>-0.028012</td>\n",
       "      <td>-0.002817</td>\n",
       "      <td>-0.007600</td>\n",
       "      <td>0.068123</td>\n",
       "      <td>-0.007966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001356</td>\n",
       "      <td>0.005888</td>\n",
       "      <td>-0.030217</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>-0.001572</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>-0.003926</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>-0.022023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>0.015691</td>\n",
       "      <td>0.345324</td>\n",
       "      <td>-0.362134</td>\n",
       "      <td>0.566202</td>\n",
       "      <td>-0.514000</td>\n",
       "      <td>0.357032</td>\n",
       "      <td>0.237122</td>\n",
       "      <td>0.512681</td>\n",
       "      <td>-0.125743</td>\n",
       "      <td>0.426377</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166757</td>\n",
       "      <td>0.016831</td>\n",
       "      <td>0.006590</td>\n",
       "      <td>0.043331</td>\n",
       "      <td>-0.030468</td>\n",
       "      <td>-0.047079</td>\n",
       "      <td>-0.128257</td>\n",
       "      <td>-0.062733</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>-0.765074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>-0.186303</td>\n",
       "      <td>0.015731</td>\n",
       "      <td>-0.053965</td>\n",
       "      <td>0.045016</td>\n",
       "      <td>-0.025141</td>\n",
       "      <td>0.040629</td>\n",
       "      <td>-0.013108</td>\n",
       "      <td>0.057805</td>\n",
       "      <td>0.026377</td>\n",
       "      <td>0.031692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032933</td>\n",
       "      <td>-0.001036</td>\n",
       "      <td>-0.000864</td>\n",
       "      <td>-0.006507</td>\n",
       "      <td>-0.003710</td>\n",
       "      <td>0.023788</td>\n",
       "      <td>0.043801</td>\n",
       "      <td>0.019615</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>-0.023131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>0.083545</td>\n",
       "      <td>0.409689</td>\n",
       "      <td>-0.361224</td>\n",
       "      <td>0.558228</td>\n",
       "      <td>-0.440750</td>\n",
       "      <td>0.458427</td>\n",
       "      <td>0.186858</td>\n",
       "      <td>0.583383</td>\n",
       "      <td>-0.118219</td>\n",
       "      <td>0.419981</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117098</td>\n",
       "      <td>-0.038339</td>\n",
       "      <td>0.005598</td>\n",
       "      <td>0.010316</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>-0.018872</td>\n",
       "      <td>-0.047550</td>\n",
       "      <td>0.015355</td>\n",
       "      <td>-0.040593</td>\n",
       "      <td>-0.607602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>0.061681</td>\n",
       "      <td>0.482065</td>\n",
       "      <td>-0.414111</td>\n",
       "      <td>0.629455</td>\n",
       "      <td>-0.488810</td>\n",
       "      <td>0.536953</td>\n",
       "      <td>0.208221</td>\n",
       "      <td>0.671177</td>\n",
       "      <td>-0.168892</td>\n",
       "      <td>0.478597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097448</td>\n",
       "      <td>-0.052312</td>\n",
       "      <td>0.007040</td>\n",
       "      <td>-0.011780</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>-0.017955</td>\n",
       "      <td>-0.021582</td>\n",
       "      <td>-0.007595</td>\n",
       "      <td>-0.014329</td>\n",
       "      <td>-0.645880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>0.125460</td>\n",
       "      <td>0.364395</td>\n",
       "      <td>-0.304459</td>\n",
       "      <td>0.461455</td>\n",
       "      <td>-0.347271</td>\n",
       "      <td>0.412840</td>\n",
       "      <td>0.138430</td>\n",
       "      <td>0.513496</td>\n",
       "      <td>-0.117791</td>\n",
       "      <td>0.342936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064925</td>\n",
       "      <td>-0.045608</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>-0.015717</td>\n",
       "      <td>0.012731</td>\n",
       "      <td>-0.009792</td>\n",
       "      <td>-0.002876</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>-0.433210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>0.002581</td>\n",
       "      <td>-0.135901</td>\n",
       "      <td>0.066535</td>\n",
       "      <td>-0.151220</td>\n",
       "      <td>0.125591</td>\n",
       "      <td>-0.150793</td>\n",
       "      <td>-0.062831</td>\n",
       "      <td>-0.165471</td>\n",
       "      <td>0.071668</td>\n",
       "      <td>-0.112968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040668</td>\n",
       "      <td>0.018987</td>\n",
       "      <td>-0.015186</td>\n",
       "      <td>0.015674</td>\n",
       "      <td>-0.026306</td>\n",
       "      <td>-0.005449</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.018489</td>\n",
       "      <td>-0.022599</td>\n",
       "      <td>0.168335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>-0.053254</td>\n",
       "      <td>-0.057802</td>\n",
       "      <td>0.169741</td>\n",
       "      <td>-0.126551</td>\n",
       "      <td>0.059128</td>\n",
       "      <td>-0.115682</td>\n",
       "      <td>-0.034539</td>\n",
       "      <td>-0.153523</td>\n",
       "      <td>0.047665</td>\n",
       "      <td>-0.133251</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166644</td>\n",
       "      <td>0.084518</td>\n",
       "      <td>0.030575</td>\n",
       "      <td>-0.003536</td>\n",
       "      <td>-0.005150</td>\n",
       "      <td>0.016914</td>\n",
       "      <td>0.040644</td>\n",
       "      <td>-0.170808</td>\n",
       "      <td>0.265242</td>\n",
       "      <td>0.105667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>-0.009050</td>\n",
       "      <td>-0.027774</td>\n",
       "      <td>0.075674</td>\n",
       "      <td>-0.018827</td>\n",
       "      <td>0.024099</td>\n",
       "      <td>-0.011328</td>\n",
       "      <td>0.015312</td>\n",
       "      <td>-0.032777</td>\n",
       "      <td>-0.145706</td>\n",
       "      <td>0.041952</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.276748</td>\n",
       "      <td>0.064439</td>\n",
       "      <td>-0.018922</td>\n",
       "      <td>0.044715</td>\n",
       "      <td>0.017551</td>\n",
       "      <td>0.212001</td>\n",
       "      <td>0.005149</td>\n",
       "      <td>0.066672</td>\n",
       "      <td>0.137314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>0.120674</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>-0.019794</td>\n",
       "      <td>-0.012436</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>-0.024251</td>\n",
       "      <td>0.017347</td>\n",
       "      <td>-0.033019</td>\n",
       "      <td>0.040159</td>\n",
       "      <td>-0.068406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001788</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>-0.041898</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>-0.131154</td>\n",
       "      <td>-0.000655</td>\n",
       "      <td>-0.042049</td>\n",
       "      <td>0.004347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>0.057309</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>0.065956</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-0.011269</td>\n",
       "      <td>0.070587</td>\n",
       "      <td>-0.043089</td>\n",
       "      <td>-0.199210</td>\n",
       "      <td>-0.003574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064439</td>\n",
       "      <td>-0.001788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016467</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>-0.003970</td>\n",
       "      <td>-0.133569</td>\n",
       "      <td>0.133815</td>\n",
       "      <td>-0.145827</td>\n",
       "      <td>-0.014876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>-0.014907</td>\n",
       "      <td>-0.021855</td>\n",
       "      <td>-0.010173</td>\n",
       "      <td>0.011504</td>\n",
       "      <td>-0.027029</td>\n",
       "      <td>-0.011593</td>\n",
       "      <td>-0.015520</td>\n",
       "      <td>-0.005589</td>\n",
       "      <td>0.014176</td>\n",
       "      <td>0.020355</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018922</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>-0.016467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005459</td>\n",
       "      <td>-0.017365</td>\n",
       "      <td>-0.038718</td>\n",
       "      <td>-0.003196</td>\n",
       "      <td>-0.007936</td>\n",
       "      <td>-0.038307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>-0.230721</td>\n",
       "      <td>-0.029900</td>\n",
       "      <td>0.036848</td>\n",
       "      <td>-0.031845</td>\n",
       "      <td>-0.003095</td>\n",
       "      <td>-0.028612</td>\n",
       "      <td>-0.030894</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>0.069131</td>\n",
       "      <td>-0.000761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044715</td>\n",
       "      <td>-0.041898</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.005459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013525</td>\n",
       "      <td>0.032789</td>\n",
       "      <td>0.111050</td>\n",
       "      <td>-0.062122</td>\n",
       "      <td>0.018527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>-0.039468</td>\n",
       "      <td>0.013148</td>\n",
       "      <td>-0.001541</td>\n",
       "      <td>-0.015140</td>\n",
       "      <td>0.036056</td>\n",
       "      <td>0.025527</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>-0.003199</td>\n",
       "      <td>0.018408</td>\n",
       "      <td>-0.023971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017551</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>-0.003970</td>\n",
       "      <td>-0.017365</td>\n",
       "      <td>0.013525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036792</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>-0.009430</td>\n",
       "      <td>0.022202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>-0.043728</td>\n",
       "      <td>0.055246</td>\n",
       "      <td>-0.028841</td>\n",
       "      <td>0.041601</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>0.100064</td>\n",
       "      <td>-0.080781</td>\n",
       "      <td>0.074117</td>\n",
       "      <td>0.161306</td>\n",
       "      <td>0.056621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212001</td>\n",
       "      <td>-0.131154</td>\n",
       "      <td>-0.133569</td>\n",
       "      <td>-0.038718</td>\n",
       "      <td>0.032789</td>\n",
       "      <td>0.036792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004891</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>0.073282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>0.000348</td>\n",
       "      <td>-0.059056</td>\n",
       "      <td>-0.058482</td>\n",
       "      <td>-0.011104</td>\n",
       "      <td>0.020159</td>\n",
       "      <td>0.012223</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>0.063947</td>\n",
       "      <td>-0.021775</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005149</td>\n",
       "      <td>-0.000655</td>\n",
       "      <td>0.133815</td>\n",
       "      <td>-0.003196</td>\n",
       "      <td>0.111050</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>-0.004891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020078</td>\n",
       "      <td>0.037652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>-0.005228</td>\n",
       "      <td>-0.149922</td>\n",
       "      <td>-0.398742</td>\n",
       "      <td>-0.106823</td>\n",
       "      <td>0.068051</td>\n",
       "      <td>-0.228017</td>\n",
       "      <td>0.157301</td>\n",
       "      <td>0.155748</td>\n",
       "      <td>-0.038307</td>\n",
       "      <td>-0.033937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066672</td>\n",
       "      <td>-0.042049</td>\n",
       "      <td>-0.145827</td>\n",
       "      <td>-0.007936</td>\n",
       "      <td>-0.062122</td>\n",
       "      <td>-0.009430</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>0.020078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>-0.067392</td>\n",
       "      <td>-0.393192</td>\n",
       "      <td>0.385028</td>\n",
       "      <td>-0.586907</td>\n",
       "      <td>0.546648</td>\n",
       "      <td>-0.365313</td>\n",
       "      <td>-0.222903</td>\n",
       "      <td>-0.532240</td>\n",
       "      <td>0.065579</td>\n",
       "      <td>-0.431281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137314</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>-0.014876</td>\n",
       "      <td>-0.038307</td>\n",
       "      <td>0.018527</td>\n",
       "      <td>0.022202</td>\n",
       "      <td>0.073282</td>\n",
       "      <td>0.037652</td>\n",
       "      <td>0.041569</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "Time    1.000000  0.153592 -0.065739 -0.155990 -0.126358  0.178835 -0.026117   \n",
       "V1      0.153592  1.000000 -0.338804  0.537571 -0.336351  0.424820  0.148526   \n",
       "V2     -0.065739 -0.338804  1.000000 -0.472027  0.289252 -0.430043 -0.059691   \n",
       "V3     -0.155990  0.537571 -0.472027  1.000000 -0.461475  0.538608  0.212974   \n",
       "V4     -0.126358 -0.336351  0.289252 -0.461475  1.000000 -0.298284 -0.148585   \n",
       "V5      0.178835  0.424820 -0.430043  0.538608 -0.298284  1.000000  0.132061   \n",
       "V6     -0.026117  0.148526 -0.059691  0.212974 -0.148585  0.132061  1.000000   \n",
       "V7      0.116719  0.576406 -0.436903  0.682578 -0.455635  0.585705  0.128049   \n",
       "V8     -0.072224 -0.072854  0.022213 -0.139669  0.063614 -0.150808 -0.188177   \n",
       "V9      0.041552  0.294227 -0.300212  0.416900 -0.347880  0.331799  0.120740   \n",
       "V10     0.090201  0.461892 -0.443536  0.638050 -0.477917  0.485033  0.198203   \n",
       "V11    -0.239900 -0.329347  0.317739 -0.487018  0.422903 -0.330921 -0.185495   \n",
       "V12     0.140374  0.411815 -0.414163  0.607054 -0.517222  0.438550  0.221911   \n",
       "V13    -0.067214 -0.032153  0.010934 -0.017727  0.004350 -0.028012 -0.002817   \n",
       "V14     0.015691  0.345324 -0.362134  0.566202 -0.514000  0.357032  0.237122   \n",
       "V15    -0.186303  0.015731 -0.053965  0.045016 -0.025141  0.040629 -0.013108   \n",
       "V16     0.083545  0.409689 -0.361224  0.558228 -0.440750  0.458427  0.186858   \n",
       "V17     0.061681  0.482065 -0.414111  0.629455 -0.488810  0.536953  0.208221   \n",
       "V18     0.125460  0.364395 -0.304459  0.461455 -0.347271  0.412840  0.138430   \n",
       "V19     0.002581 -0.135901  0.066535 -0.151220  0.125591 -0.150793 -0.062831   \n",
       "V20    -0.053254 -0.057802  0.169741 -0.126551  0.059128 -0.115682 -0.034539   \n",
       "V21    -0.009050 -0.027774  0.075674 -0.018827  0.024099 -0.011328  0.015312   \n",
       "V22     0.120674  0.005708 -0.019794 -0.012436  0.027532 -0.024251  0.017347   \n",
       "V23     0.057309  0.003524  0.065956  0.004547  0.000180 -0.011269  0.070587   \n",
       "V24    -0.014907 -0.021855 -0.010173  0.011504 -0.027029 -0.011593 -0.015520   \n",
       "V25    -0.230721 -0.029900  0.036848 -0.031845 -0.003095 -0.028612 -0.030894   \n",
       "V26    -0.039468  0.013148 -0.001541 -0.015140  0.036056  0.025527  0.002919   \n",
       "V27    -0.043728  0.055246 -0.028841  0.041601  0.006340  0.100064 -0.080781   \n",
       "V28     0.000348 -0.059056 -0.058482 -0.011104  0.020159  0.012223  0.012347   \n",
       "Amount -0.005228 -0.149922 -0.398742 -0.106823  0.068051 -0.228017  0.157301   \n",
       "Class  -0.067392 -0.393192  0.385028 -0.586907  0.546648 -0.365313 -0.222903   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "Time    0.116719 -0.072224  0.041552  ... -0.009050  0.120674  0.057309   \n",
       "V1      0.576406 -0.072854  0.294227  ... -0.027774  0.005708  0.003524   \n",
       "V2     -0.436903  0.022213 -0.300212  ...  0.075674 -0.019794  0.065956   \n",
       "V3      0.682578 -0.139669  0.416900  ... -0.018827 -0.012436  0.004547   \n",
       "V4     -0.455635  0.063614 -0.347880  ...  0.024099  0.027532  0.000180   \n",
       "V5      0.585705 -0.150808  0.331799  ... -0.011328 -0.024251 -0.011269   \n",
       "V6      0.128049 -0.188177  0.120740  ...  0.015312  0.017347  0.070587   \n",
       "V7      1.000000  0.027668  0.444805  ... -0.032777 -0.033019 -0.043089   \n",
       "V8      0.027668  1.000000 -0.050410  ... -0.145706  0.040159 -0.199210   \n",
       "V9      0.444805 -0.050410  1.000000  ...  0.041952 -0.068406 -0.003574   \n",
       "V10     0.668804 -0.063814  0.467092  ... -0.003417 -0.068820 -0.005168   \n",
       "V11    -0.471116  0.109537 -0.367387  ...  0.103983  0.022540 -0.009979   \n",
       "V12     0.604248 -0.117515  0.458851  ... -0.087254 -0.041383  0.008283   \n",
       "V13    -0.007600  0.068123 -0.007966  ... -0.001356  0.005888 -0.030217   \n",
       "V14     0.512681 -0.125743  0.426377  ... -0.166757  0.016831  0.006590   \n",
       "V15     0.057805  0.026377  0.031692  ...  0.032933 -0.001036 -0.000864   \n",
       "V16     0.583383 -0.118219  0.419981  ... -0.117098 -0.038339  0.005598   \n",
       "V17     0.671177 -0.168892  0.478597  ... -0.097448 -0.052312  0.007040   \n",
       "V18     0.513496 -0.117791  0.342936  ... -0.064925 -0.045608  0.003155   \n",
       "V19    -0.165471  0.071668 -0.112968  ...  0.040668  0.018987 -0.015186   \n",
       "V20    -0.153523  0.047665 -0.133251  ... -0.166644  0.084518  0.030575   \n",
       "V21    -0.032777 -0.145706  0.041952  ...  1.000000 -0.276748  0.064439   \n",
       "V22    -0.033019  0.040159 -0.068406  ... -0.276748  1.000000 -0.001788   \n",
       "V23    -0.043089 -0.199210 -0.003574  ...  0.064439 -0.001788  1.000000   \n",
       "V24    -0.005589  0.014176  0.020355  ... -0.018922  0.010127 -0.016467   \n",
       "V25     0.007048  0.069131 -0.000761  ...  0.044715 -0.041898  0.000223   \n",
       "V26    -0.003199  0.018408 -0.023971  ...  0.017551  0.003013 -0.003970   \n",
       "V27     0.074117  0.161306  0.056621  ...  0.212001 -0.131154 -0.133569   \n",
       "V28     0.063947 -0.021775  0.064084  ...  0.005149 -0.000655  0.133815   \n",
       "Amount  0.155748 -0.038307 -0.033937  ...  0.066672 -0.042049 -0.145827   \n",
       "Class  -0.532240  0.065579 -0.431281  ...  0.137314  0.004347 -0.014876   \n",
       "\n",
       "             V24       V25       V26       V27       V28    Amount     Class  \n",
       "Time   -0.014907 -0.230721 -0.039468 -0.043728  0.000348 -0.005228 -0.067392  \n",
       "V1     -0.021855 -0.029900  0.013148  0.055246 -0.059056 -0.149922 -0.393192  \n",
       "V2     -0.010173  0.036848 -0.001541 -0.028841 -0.058482 -0.398742  0.385028  \n",
       "V3      0.011504 -0.031845 -0.015140  0.041601 -0.011104 -0.106823 -0.586907  \n",
       "V4     -0.027029 -0.003095  0.036056  0.006340  0.020159  0.068051  0.546648  \n",
       "V5     -0.011593 -0.028612  0.025527  0.100064  0.012223 -0.228017 -0.365313  \n",
       "V6     -0.015520 -0.030894  0.002919 -0.080781  0.012347  0.157301 -0.222903  \n",
       "V7     -0.005589  0.007048 -0.003199  0.074117  0.063947  0.155748 -0.532240  \n",
       "V8      0.014176  0.069131  0.018408  0.161306 -0.021775 -0.038307  0.065579  \n",
       "V9      0.020355 -0.000761 -0.023971  0.056621  0.064084 -0.033937 -0.431281  \n",
       "V10     0.017805  0.005578 -0.011732  0.070480  0.058080 -0.044629 -0.646016  \n",
       "V11    -0.035886  0.019952  0.038492  0.088542  0.025035  0.010215  0.594135  \n",
       "V12     0.017082  0.007290 -0.028776 -0.036853 -0.012147 -0.005060 -0.701934  \n",
       "V13     0.006404  0.000477 -0.001572  0.006826 -0.003926  0.015193 -0.022023  \n",
       "V14     0.043331 -0.030468 -0.047079 -0.128257 -0.062733  0.006744 -0.765074  \n",
       "V15    -0.006507 -0.003710  0.023788  0.043801  0.019615  0.005162 -0.023131  \n",
       "V16     0.010316  0.003518 -0.018872 -0.047550  0.015355 -0.040593 -0.607602  \n",
       "V17    -0.011780  0.003371 -0.017955 -0.021582 -0.007595 -0.014329 -0.645880  \n",
       "V18    -0.015717  0.012731 -0.009792 -0.002876  0.003128  0.014113 -0.433210  \n",
       "V19     0.015674 -0.026306 -0.005449  0.002957  0.018489 -0.022599  0.168335  \n",
       "V20    -0.003536 -0.005150  0.016914  0.040644 -0.170808  0.265242  0.105667  \n",
       "V21    -0.018922  0.044715  0.017551  0.212001  0.005149  0.066672  0.137314  \n",
       "V22     0.010127 -0.041898  0.003013 -0.131154 -0.000655 -0.042049  0.004347  \n",
       "V23    -0.016467  0.000223 -0.003970 -0.133569  0.133815 -0.145827 -0.014876  \n",
       "V24     1.000000  0.005459 -0.017365 -0.038718 -0.003196 -0.007936 -0.038307  \n",
       "V25     0.005459  1.000000  0.013525  0.032789  0.111050 -0.062122  0.018527  \n",
       "V26    -0.017365  0.013525  1.000000  0.036792  0.009095 -0.009430  0.022202  \n",
       "V27    -0.038718  0.032789  0.036792  1.000000 -0.004891  0.004897  0.073282  \n",
       "V28    -0.003196  0.111050  0.009095 -0.004891  1.000000  0.020078  0.037652  \n",
       "Amount -0.007936 -0.062122 -0.009430  0.004897  0.020078  1.000000  0.041569  \n",
       "Class  -0.038307  0.018527  0.022202  0.073282  0.037652  0.041569  1.000000  \n",
       "\n",
       "[31 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f665e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Class',axis =1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "504642e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddcd2faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56dbf24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rushima\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression()\n",
    "log_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4d5f3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      " [[6737   15]\n",
      " [  68  299]]\n",
      " Accuracy : 0.9883410591375194\n",
      "Classication Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6752\n",
      "           1       0.95      0.81      0.88       367\n",
      "\n",
      "    accuracy                           0.99      7119\n",
      "   macro avg       0.97      0.91      0.94      7119\n",
      "weighted avg       0.99      0.99      0.99      7119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trainig\n",
    "y_pred_train = log_clf.predict(x_train)\n",
    "con_mat = confusion_matrix(y_train,y_pred_train)\n",
    "print(\"Confusion Matrix :\\n\",con_mat)\n",
    "accuracy_train = accuracy_score(y_train,y_pred_train)\n",
    "print(\" Accuracy :\",accuracy_train)\n",
    "clf_report = classification_report(y_train,y_pred_train)\n",
    "print(\"Classication Report : \\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df34bb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      " [[2241    7]\n",
      " [  20  105]]\n",
      " Accuracy : 0.988621997471555\n",
      "Classication Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2248\n",
      "           1       0.94      0.84      0.89       125\n",
      "\n",
      "    accuracy                           0.99      2373\n",
      "   macro avg       0.96      0.92      0.94      2373\n",
      "weighted avg       0.99      0.99      0.99      2373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "y_pred = log_clf.predict(x_test)\n",
    "con_mat = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix :\\n\",con_mat)\n",
    "accuracy_test = accuracy_score(y_test,y_pred)\n",
    "print(\" Accuracy :\",accuracy_test)\n",
    "clf_report = classification_report(y_test,y_pred)\n",
    "print(\"Classication Report : \\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14c3a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {'accuracy_train':[],'accuracy_test': []}\n",
    "index = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43f388ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logestic Regression\n",
    "result_dict['accuracy_train'].append(accuracy_test)\n",
    "result_dict['accuracy_test'].append(accuracy_train)\n",
    "index.append('logistic_reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cc8fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83302fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Class',axis = 1)\n",
    "y = df['Class']\n",
    "smt = SMOTE()\n",
    "x_new,y_new = smt.fit_resample(x,y)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_new,y_new,test_size=0.25,random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f35c5ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model_over = LogisticRegression()\n",
    "log_model_over.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29db4348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      " [[6619  146]\n",
      " [ 268 6467]]\n",
      " Accuracy : 0.9693333333333334\n",
      "Classication Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      6765\n",
      "           1       0.98      0.96      0.97      6735\n",
      "\n",
      "    accuracy                           0.97     13500\n",
      "   macro avg       0.97      0.97      0.97     13500\n",
      "weighted avg       0.97      0.97      0.97     13500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trainig\n",
    "y_pred_train = log_model_over.predict(x_train)\n",
    "con_mat = confusion_matrix(y_train,y_pred_train)\n",
    "print(\"Confusion Matrix :\\n\",con_mat)\n",
    "acc_train = accuracy_score(y_train,y_pred_train)\n",
    "print(\" Accuracy :\",acc_train)\n",
    "clf_report = classification_report(y_train,y_pred_train)\n",
    "print(\"Classication Report : \\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19c24d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      " [[2194   41]\n",
      " [  74 2191]]\n",
      " Accuracy : 0.9744444444444444\n",
      "Classication Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      2235\n",
      "           1       0.98      0.97      0.97      2265\n",
      "\n",
      "    accuracy                           0.97      4500\n",
      "   macro avg       0.97      0.97      0.97      4500\n",
      "weighted avg       0.97      0.97      0.97      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "y_pred = log_model_over.predict(x_test)\n",
    "con_mat = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix :\\n\",con_mat)\n",
    "acc_test = accuracy_score(y_test,y_pred)\n",
    "print(\" Accuracy :\",acc_test)\n",
    "clf_report = classification_report(y_test,y_pred)\n",
    "print(\"Classication Report : \\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45e7e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logestic_Regression_After_Oversampling\n",
    "result_dict['accuracy_train'].append(acc_test)\n",
    "result_dict['accuracy_test'].append(acc_train)\n",
    "index.append('logistic_after_oversampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91aecd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8aef77d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_model =DecisionTreeClassifier()\n",
    "dec_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91bdf546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      " [[6765    0]\n",
      " [   0 6735]]\n",
      " Accuracy : 1.0\n",
      "Classication Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6765\n",
      "           1       1.00      1.00      1.00      6735\n",
      "\n",
      "    accuracy                           1.00     13500\n",
      "   macro avg       1.00      1.00      1.00     13500\n",
      "weighted avg       1.00      1.00      1.00     13500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trainig\n",
    "y_pred_train = dec_model.predict(x_train)\n",
    "con_mat = confusion_matrix(y_train,y_pred_train)\n",
    "print(\"Confusion Matrix :\\n\",con_mat)\n",
    "accuracy_train = accuracy_score(y_train,y_pred_train)\n",
    "print(\" Accuracy :\",accuracy_train)\n",
    "clf_report = classification_report(y_train,y_pred_train)\n",
    "print(\"Classication Report : \\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "461fd2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      " [[2178   57]\n",
      " [  44 2221]]\n",
      " Accuracy : 0.9775555555555555\n",
      "Classication Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      2235\n",
      "           1       0.97      0.98      0.98      2265\n",
      "\n",
      "    accuracy                           0.98      4500\n",
      "   macro avg       0.98      0.98      0.98      4500\n",
      "weighted avg       0.98      0.98      0.98      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "y_pred = dec_model.predict(x_test)\n",
    "con_mat = confusion_matrix(y_test,y_pred)\n",
    "print(\"Confusion Matrix :\\n\",con_mat)\n",
    "accuracy_test = accuracy_score(y_test,y_pred)\n",
    "print(\" Accuracy :\",accuracy_test)\n",
    "clf_report = classification_report(y_test,y_pred)\n",
    "print(\"Classication Report : \\n\",clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc0099f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision_Tree\n",
    "result_dict['accuracy_train'].append(accuracy_test)\n",
    "result_dict['accuracy_test'].append(accuracy_train)\n",
    "index.append(\"Decision_Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfe8076e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logistic_reg</th>\n",
       "      <td>0.988622</td>\n",
       "      <td>0.988341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic_after_oversampling</th>\n",
       "      <td>0.974444</td>\n",
       "      <td>0.969333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_Tree</th>\n",
       "      <td>0.977556</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             accuracy_train  accuracy_test\n",
       "logistic_reg                       0.988622       0.988341\n",
       "logistic_after_oversampling        0.974444       0.969333\n",
       "Decision_Tree                      0.977556       1.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Result_df = pd.DataFrame(result_dict,index =index )\n",
    "Final_Result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05b92f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e09cca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"log_clf.pkl\",'wb') as f:\n",
    "    pickle.dump(log_clf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec34e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf34197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
